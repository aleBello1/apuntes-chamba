

////////////////////////////////////////TEORIA///////////////////////////////////////////////////

Es una software opensource usado para automatizar la implementación, el escalado y la 
administración de aplicaciones en contenedores.

El principal propósito de kubernetes es llevar varios contenedores en producción.

Se abrevia como k8s porque entre la letra k y la letra s hay 8 letras.


PROBLEMAS QUE RESUELVE

Problema 1: En un escenario donde los contenedores se ejecutan en una misma máquina virtual, si 
uno de ellos se detiene o falla, puede pasar un tiempo considerable antes de que el equipo lo 
detecte. Además, el reinicio del contenedor tendría que realizarse de manera manual.
Cuando el número de contenedores es elevado, el monitoreo y la recuperación manual se vuelve 
extremadamente tedioso. Kubernetes soluciona este problema al detectar automáticamente los fallos
y reiniciar los contenedores sin intervención humana.

Problema 2: En un escenario donde cada componente de la aplicación se ejecuta en un contenedor 
dentro de la misma máquina virtual, un incremento significativo de tráfico puede provocar que un 
solo contenedor se sature.
Kubernetes resuelve este problema mediante el autoescalado, creando automáticamente múltiples 
réplicas de los contenedores que requieren mayor capacidad de procesamiento. También, cuando 
kubernetes tenga que crear las replicas de contenedores, se encargara de distribuir uniformemente
el trafico entrante entre los diferentes contenedores.

A pesar de estos problemas, el servicio en la nube de aws llamado ecs si puede combatir estos
situaciones porque provee reemplazo de contenedores en caso de problemas, auto-escalado y 
balanceo de carga. **
Pero la desventaja de usar un servicio como este, es que si algún dia queremos migrarnos a 
otro provedoor de servicios en la nube como gcp, azure, etc. tendríamos que aprender como se usa
ese servicio en la nube.
Al usar kubernets, es como tener una solución portable entre las nubes, es decir lo que hagamos
en kubernetes se puede migrar fácilmente entre aws, gcp, azure, etc porque es un software 
que se puede intslar en cualquier MV de los provedores de la nube antes mencionados ******


ARQUITECTURA Y COMPONENTES PRINCIPALES DE KUBERNETES

Worker node: es una máquina (VM o física).
	Ejecuta a los pods.
	Reportan su estado al control plane
	Dentro de este viven: pods, kubletet y contenedores.
	
pod *Hay mas teoría adelante de esto*

Kubelet: Es un proceso que se ejecuta en cada worker node y es el encargado de comunicarse con 
	el control plane.
	Administra los pods dentro de un worker node: Se encarga de Crear y destruir pods, 
	verifica la salud de los contenedores dentro de los pods y se encarga de autogerar
	a los contenedores si fallan, según la política de reinicio del Pod. También mueve a 	los pods dentro de los worker nods.
	
kube-proxy: es un componente de Kubernetes que corre en cada worker node y se encarga de que el 
	tráfico de red llegue al Pod correcto.
	Encargado del tráfico de entrada y salida ademas balanceo interno.

Master node: Se encarga de administrar a los worker node mediante un panel de control.
	El master node siempre debe estar en una MV distinta a los worker node, porque si la	
	MV donde este el master node se cae, ya no se podrá gestionar los woker node. ***
	Decide qué se ejecuta, dónde y cómo.
	Componentes: 
	- Scheduler: Decide en qué worker node se ejecuta cada pod.
		Si los pods se deben cambiar de nodo, se eliminan y se crean nuevos en otro nodo.
		Considera CPU, memoria, afinidad, etc.
	- kube Controller Manager: Vigila que el estado real coincida con el deseado.
		Ejemplo: “Quiero 3 pods”, Hay 2 → crea 1 más
	- cloud controller manager: Permite que Kubernetes se integre con un proveedor de nube 
		(AWS, GCP, Azure, etc.).
	- etcd: Base de datos (clave - valor) donde se guarda todas las configuraciones de 
		kubernets y nuestro estado final deseado.

Cluster: es un conjunto de máquinas que trabajan juntas como un solo sistema para ejecutar 
	aplicaciones.
	Un cluster esta conformado por un solo master node y varios worker nodes. Todas las 
	MV están en la misma red.	
	Permite: Escalar aplicaciones, Alta disponibilidad y Auto-recuperación. Ejemplo: 
	Se cae un pod → se crea otro; Hay mucho tráfico → se crean más pods; Se cae un node → los
	pods se mueven a otro.

kubctl: Kube control. Es la herramienta de línea de comandos que usas para comunicarte con 
	Kubernetes.
	es un CLI (Command Line Interface) que te permite enviar instrucciones al cluster de
	Kubernetes a través del API Server.
	kubectl es el cliente
	API Server es el servidor
	Se comunican por HTTP/REST


HERRAMIENTAS NECESARIAS

Estas herramientas se necesitan instalar en cada MV.

Minikube: Herramienta que nos permite desarrollar con kubernetes.
	Permite crear un cluster de Kubernetes local en tu máquina.
	Se usa para: Aprender Kubernetes, Probar deployments, Hacer pruebas antes de producción
	y Desarrollo local. 
	No se usa para producción y No es un cluster multi-nodo real (aunque puede simular)

Documentación para la instalación de kube-ctl:
https://kubernetes.io/docs/tasks/tools/install-kubectl-windows/

Se debe tener instalado chocolatey.

choco -v -> versificarlo con este comando.

choco upgrade chocolatey -> Para actualizar chocolatey.

choco install kubernetes-cli -> Instalar kubectl

kubectl version --client -> Verificar que este instalado.

Documentación para la instalación de mini-kube:
https://minikube.sigs.k8s.io/docs/start/?arch=%2Fwindows%2Fx86-64%2Fstable%2F.exe+download

Es puro next la instalación.

*Lo siguietne se hace en cmd*

Dirigirse a esta ruta:
cd %USERPROFILE%

crear la carpeta
mkdir .kube

Ingresar y crear este archivo:
cd .kube
New-Item config -type file

Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Hyper-V -All -> Para habilitar 
	hyper-v en caso de que este deshabilitado.

minikube start --driver=hyperv ó 
minikube start --driver=Docker -> Iniciar mini-kube con hyper-v.
	Esto provocara que minkube cree una sola mv, es decir, habrá un solo nodo para el 	cluster.
	Usar Docker es buena alternativa en Windows 10 pro u 11 pro.
	Comenzara a descargar todos los componentes de la arquitectura de kubernetes.
	Hacer esto consume bastante ram y la seguirá consumiendo aun cuando este comando
	se haya realizado correctamente porque corre en segundo plano. ***
	- minikube start --driver=hyperv --memory=2048 --cpus=2 -> Para iniciarlo con menos ram.
	- --nodes=n -> Para iniciar minikube con una cantidad de nodos diferente al defaultat (1)
		Hacer esto provocara que el consumo de RAM y cpu por cada nodo sea mayor porque
		es basicmante crear mas de una MV. ****
		Entonces pe hacer esto: minikube start --nodes=3 --memory=2048 --cpus=2 
		implicaría crear 3 nodos con 2gb de ram y 2 cpus cada uno.
		
minikube status -> Para verificar que todo este corriendo correctamente.

minikube stop -> detener Minikube (sin borrarlo).
	Esto se hace para liberar RAM temporalmente.


OBJETOS DE KUBERNETES

pod: Es la unidad más pequeña que Kubernetes puede crear. Un pod contiene, administra y Ejecuta
	contenedores.
	Todos los contenedores dentro de un pod se pueden comunicar mediante el localhost.
	Los contenedores dentro de un pod: Comparten IP, Comparten puertos y comparten volúmenes.
	Normalmente solo contiene un contendor pero si puede contener mas de uno.
	Cada pod tiene su propia ip.
	Debido a que los pods son efímeros: son eliminados, reemplazados según se requiere es
	por eso que los volúmenes no están dentro de un pod.

Deployments: Controla a los pods de manera automatizada.
	Lo ideal no es crear los pods manualmente si no usar deplyomente para que lo cree 
	por nosotros.	
	Aqui se configura el estado deseado del despligue y kubenerest se encarga de mantener ese
	estado.
	Puede ser eliminados, modificados, detenidos y revertirdos a una versión anterior.

servicios: Nos permite conectarnos a la aplicación que corre dentro del contenedor que esta
	dentro de un pod mediante una ruta fija. 
	Ademas, agrupa un conjunto de pods que contiene la misma parte de la app para aplicarles
	un load balancer asi que también aplica auto-escalado.

namespace: Permite organizar el espacio de trabajo.

volumen: Sirve para mantener persistentes los datos en un repositorio externo.

ReplicaSet: Su responsabilidad es Mantener corriendo exactamente N Pods para cada label.

Hay dos formas de crear objetos: 1. la imperativa (usando comandos) y 2. declarativa 
(supuestamente esta es la mejor forma porque se puede reutilizar los archivos de configuración
yaml).




///////////////////////////////////////PRACTICA//////////////////////////////////////////////////

PUERTOS

Hay 3 puertos distintos y pertenecen a diferentes objetos: port, targetPort y containerPor.
		Cliente  →  Service (port)  →  Pod (targetPort)  →  containerPort
containerPort → donde tu app escucha dentro del contenedor (ej: 8080)
targetPort → puerto del Pod (normalmente 8080)
port → puerto del Service (ej: 80)


CREAR DEPLOYMENT (FORMA CON COMANDOS)

Al igual que con los contenedores, se crea primero el deployment de un pod que almacena un
contendor que almacena una db y después el que almacena la app. **

*Se debe tener encendido el minikube*

minikube image pull name-image -> Para que minikube descargue cierta imagen de Docker hub.
	En teoría, el comando de abajo por defecto baja descarga la imagen, pero en ocasiones
	no lo hace y es mejor bajar la imagen por separado con este comando. 

kubctl create deployment nombreDeployment --image=nombreImagen:version --port=numPuertoInterno ->
	Crea un deployment, el cual crea un replicaSet y su propósito es crear a los pods.
	Este comando no maneja variables de ambiente asi que para crear un deploymente para
	una db como mysql no seria posible. Para lograr una funcionalidad asi se 
	usaría la forma declarativa (con un archivo yaml).
	Usalmente el nombre del deployment será igual al nombre del contenedor.
	La imagen siempre se descargara de Docker hub. *** 
	El puerto interno es el puerdo donde tu aplicación está escuchando.
	- --dry-run=client -o yaml > nombreArchivo.yaml -> Si se pasa esta opción se crea el
		esqueleto de un manifiesto (archivo de configuración yaml) pero no lo crea en 
		el cluster si no en nuestra maquina local. 
		Este archivo se usa para definir todas las configuración del deploymente pero
		es usado principalmente para especificar y pasarle valores a las variables de 
		ambiente que necesite un contenedor. ***
		Con esta configuración el deployment no será creado en el cluster, únicamente 
		se creara el archivo de configuración yaml.

kubctl get deployments ó
kubectl get deploy -> Muestra todos los deployments.
	No muestra información detallada.
	La columna ready muestra la cantidad de pods que están listos del un total de pods 
	deseados.

kubctl get pods -> Muestra todos los pods.
	Muestra el status y nombre de cada pod. También la cantidad de veces que se ha 
	auto-regenerado el contenedor (en la columna restart).

kubectl describe pods nombrePod -> Muestra la información de determinado pod.
	Mostra el nombre, ip (se recuerda que esta cambia a cada rato) del pod y la información
	del contenedor que almacena mostarando datos como: la imagen, el puerto, el status, las
	variables de ambiente ****, etc.
	Tambien pareciera que muestra los logs de un pod (del pod, mas no de la app) porque 	muestra ciertos sucesos en su ciclo de vida. *****

kubtcl describe deployement nombreDeploy ó 
kubtcl describe deploy nombreDeploy -> Muestra la información de determinado deployment.
	Mostrara el nombre, selector (qué etiquetas debe tener un Pod para pertenecer a este 
	Deployment), replicas: desired → cuántos Pods quiere, total → cuántos existen, available
	→ cuántos están listos, unavailable → cuántos fallaron.

kubectl logs nombrePod -> Muestra los logs de la aplicación que esta dentro de cierto pod.

kubectl delete deployment nombreDeploy -> Elimina determinado deployment.

kubectl apply -f .\nombreArchivo.yaml -> Lee determinado archivo yaml y con base en este crea o 	actualiza los recursos en el cluster para que coincidan con lo que dice el archivo.
	 

CREAR SERVICE (FORMA CON COMANDOS)

Todos los pods con el mismo nombre de etiqueta pertenecen al mismo servicio.
Service hace balanceo automático. Cada vez que llega una petición:
	Service → selecciona un Pod disponible

kubectl expose deployment nombreDeployment --port=numPuertoService --type=tipoX -> Para crear un 
	Service	a partir de un Deployment, es decir, Expone tu aplicación para que pueda ser 	accedida dentro o fuera del cluster.
	Si nos damos cuenta se crea un service con el mismo nombre que el deployment. ***
	- --port=numPuertoService -> El valor que le asignamos al puerto es el puerto que 
		usaremos para conectarnos al Service.
		Si el tipe es clusterIp se usara el valor de esta opción pero si el type es 
		nodePort se usara otro numero de puerto que kubernetes asigna por si solo, 
		aunque aun asi es obligatorio configurar esta opción.
	- --target-port=numPuertoPod -> Es el puerto del pod.
		Es muy normal que multiples pdos tengan el mismo targetPort porque cada pod
		tiene su propia ip interna.
	- --name=otroNombre -> Para especificar un nombre al serivice y sea distinto al del
		deployment.
	Tipos:
	- ClusterIP -> Permite solo comunicación interna entre los pods pertenecientes al mismo
		cluster.
		Se usa para Comunicación entre microservicios o para comunicar un backend con
		su db.
	- NodePort -> Permite que alguien fuera del cluster pueda entrar. Mas específicamente
		cada nodo (MV en el clúster) tendrá abierto el mismo puerto para recibir 
		conexiones.
		NO se usa para producción, se usa para desarrollo.
	- LoadBalancer -> Crea un balanceador externo en la nube (AWS, Azure, GCP) y asigna 
		una IP pública.
		LoadBalancer usa NodePort por debajo porque Internamente utiliza un NodePort 
		para enrutar el tráfico hacia los Pods.
		Crea un loadbalancer para distribuir las solicitudes entre los diferentes pods.
		Sirve para comunicación interna y externa, este tipo se asigna a las apps
		a las cuales nos queramos comunicar desde afuera pe con postman o un fron. ***
		
kubectl get services ó
kubectl get svc -> Muestra todos los objetos servicios junto con su información.
	De cada service mostrara su nombre, type, ports (portService y nodePort (si aplica)),
	tiempo de existencia, external-ip (Solo aparece cuando el Service es tipo: 
	loadbalancer. Es creada por aws, azure o gcp. Se usa para que los usuarios externos
	accedan), cluster-ip (la ip que los nodos utilzan para comunicarse entre ellos, no
	se puede usar para acceder desde afuera).

kubectl describe service nombreServicio -> Muestra información detallada de determinado servicio.
	Pe mostra el nombre del selector (El Service enviará tráfico a todos los Pods que tengan
	el mismo selector), los enpoints (las ips de los pods al que el service enviara el 
	trafico), nodePort (si aplica) y los events (los eventos de ciclo de vida del service).

minikube service nombreServiceApp --url -> Para conocer la ip externa de un servicio con el 
	type loadBalancer.
	Este comando solo se aplica a servicios que almancenan pods que alamcenan contenedores
	que almacenan apps y no dbs.

Para conectarse al service dependerá del type. 


Caso 1: ClusterIP ---------------------------------

Solo accesible dentro del cluster.

Desde otro Pod podrías hacer:

curl http://nombreServicio:puertoService


Caso 2: NodePort ----------------------------------

Se ejecuta kubectl get services
se Verá algo como:
mi-app   NodePort   10.96.1.5   <none>   80:nodePort/TCP

minikube ip -> Devuelve la ip del único nodo en minikube.
	Por defecto minikube solo tiene un nodo, a menos que se haya especificado distinto cuando
	se levanto.
*ó si se esta ocupando una nube (aws, azure, gcp)*
kubectl get nodes -o wide -> Muestra información de todos los nodos en el cluster.
	
curl http://ipNodo:nodePort -> La ip del nodo, puede ser la ip de cualquier nodo (MV) porque 
	todos los nodos tienen abiertos el mismo puerto. **


Caso 3: LoadBalancer ---------------------------------

°°°°°°°°° en ambiente productivo °°°°°°°°°

El debe ser seria ejecutar este comando: kubectl get services y de ahí extraer el external-ip
del serivioc que deseamos consumir.
	
	http://ipServiceExterno:puertoService


°°°°°°°°° En local con minikube °°°°°°°°° 

No existe un Load Balancer real, entonces al ejecutar el comando kubectl get services, el EXTERNAL-IP queda en: <pending>

*Abrir una terminal extra y ejecutar*
minikube tunnel -> crear una interfaz de red virtual en tu sistema.
	Crea una ruta de red en tu máquina local para simular lo que haría un 
	proveedor cloud.
	Después de ejcutarlo se deja esa terminal abierta y se regresa a la principal.

Ejecutar el kubectl get services para que ahora si muestre una external-ip del servicio.
Y ahora si podremos consumirlo como:
	
	http://ipServiceExterno:puertoService


ACTUALIZAR IMAGEN DE UN DEPLOYMENT

Esto es necesario cuando se actualiza algo en el código de la app y se necesita desplegar una
nueva versión de la app.

Primero se reconstruye la imagen (con docker build...)
Después asignarle un nuevo tag a la imagen (con docker tag...). Estamos obligados a ponerle una
nueva version a la imagen, si no kubernetes no nos dejara setearle una nueva imagen. ******
Al final, subir esa nueva imagen (docker push...).

Listar todos los pods que hay para encontrar el pod que necesita la actualización de 
imagen (kubectl get pods).
Obtener los detalles de pod que creemos tiene la imagen (docker describe pod nombrePod),
de esto extraeremos el nombre del contenedor y la imagen que esta usando actualmente.

kubectl set image deployment nombreDeploy 
	nombreContenedor=nombreUserDockerHub/nombreImagen:version -> Actualiza la imagen que usa 
		determinado contenedor.
		
Confirmar que ese pod se volvió a levantar pero con la imagen nueva (kubeclt get pods).


REPLICAS (FORMA CON COMANDOS)

Consiste en poder aumentar la cantidad de instancias de pods de un mismo deployment.

kubectl scale deployment nombreDeploy --replicas=n -> Escala el numero de instancias de un pod
	para un deployment.
	Al tener muchas injstancias de un pod, para el usuario la aplicación aparentara como
	si nunca estuviera caída porque siempre habrá una replica que atienda las solicitudes. *
	Cada que una replica se muera por culpa del mismo enpoint y la misma razón, cada que 
	kubernetes levante a la replica tardara mas y mas porque kubernetes lo considera un 
	error repetitivo. Entonces el status de un pod que se murió y revivio multiples veces por
	la misma razón, tendrá el status CrashLoopBackOff y eso significa que tardara en 
	revivir. **


CEAR DEPLOYMENT (FORMA DECLARATIVA)

apiVersion: apps/v1 -> Especifica la versión de api.
	Este valor es para los objetos deployment.

kind: Deployment -> Especifica el tipo de objeto a crear.

metadata: -> Configura información descriptiva del objeto.
	Configuraciones para esta opción:
	- name: nombreDeploy -> Define nombre del Deployment dentro del cluster.
	- namespace: nombre -> En qué espacio lógico vive el recurso.

spec: -> Especificaciones del deployment. 
	Le dices a Kubernetes cómo quieres que funcione ese Deployment.
	Configuraciones para esta opción:
	- replicas: n -> Cantidad de replicas de los pods.
		Para especificar la cantidad de pods que queremos que esten corriendo siempre.
		Si uno se cae Kubernetes crea otro automáticamente.
	- selector:
		- matchLabels:
			- app: nombreTag -> Indica el nombre de etiqueta que deben tener los pods
				para que este deployment los administré.
				Este nombre tiene que hacer match en los pods en la configuración
				de template: metadata: labels: app: nombreTag.
	- template: Especifica la configuración de los pods.
		Cada réplica será creada usando EXACTAMENTE lo que está dentro de template.
		Si cambias algo dentro de template, Kubernetes crea un nuevo ReplicaSet 
		automáticamente.
		Configuraciones para esta opción:
		- metadata:		
			- labels
				- app: nombreTag -> Especifica el label que se le pondrá a cada
					pod que el deploymente queda.
					Debe coincidir con selector: matchLabels: app: 
					nombreTag. ***+
		- spec: -> Realiza las especificaciones de los pods.
			- containers: -> Para definir los contendores que contendrá cada pod.
				- - image: nombreImagen:version -> Imagen del contendor.
				- name: nombreContenedor -> Nombre del contenedor.
				- ports:	
					- - containerPort: numPuertoInterno -> Puerto donde 
						escucha la aplicación.
				- env:
					- - name: nombreVariableAmbiente
					- value: valor -> Para pasarle variables de ambiente
						al contenedor.
						Se crea un par como este por cada variable de 
						ambiente que necesite el contenedor.
						En producción normalmente NO se definen valores 
						sensibles de esta forma, en su lugar se usan 
						configMaps y secrets.
	

CREAR SERVICE (FORMA DECLARATIVA)

kubectl expose deployment nombreDeployment --port=numPuertoService --type=tipoX 
	--target-port=numPuertoPod -o yaml > nombreArchivo.yaml -> Crear un Service.
		No lo va a crear en el cluster.
		Solo va a generar el YAML y guardarlo en un archivo.

kubectl get service nombreServicio -o yaml > nombreArchivo.yaml -> Para crear el archivo de 	
	configuración yaml a partir de un objeto service.
	Exportar la definición actual de un objeto Service que ya existe en el cluster y con
	base a esa definición crea un archivo de configuración yaml.

apiVersion: v1 -> Especifica la versión de api.
	Este valor es para los objetos service.

kind: Service -> Especifica el tipo de objeto a crear.

metadata: -> Configura información descriptiva del objeto.
	Configuraciones para esta opción:
	- name: nombreService -> Define nombre del service dentro del cluster.
	- namespace: nombre -> En qué espacio lógico vive el recurso.

spec: -> Especificaciones del service. 
	Le dices a Kubernetes cómo quieres que funcione ese service.
	Configuraciones para esta opción:
	- ports: 
		- - port: puertoService -> Especifica el puerto del service.
			Es el puerto por el cual el Service será accesible dentro del cluster (o
			externamente si aplica).
		- protocol: TCP -> Especifica el protocolo tcp.
		- targetPort: puertoPod -> Especifica el puerto del pod.
	- type: nombreTipo -> Para especificar el tipo de servicio (ClusterIp, NodePort o 	
		LoadBalancer).
		Cuando el type es nodeport o loadbalancer se puede especificar el valor de 
		nodeport
	- selector: 
		app: nombreTag -> Para seleccionar un grupo de pods, los cuales deben tener este
			nombre.
			Este Service enviará tráfico a todos los Pods que tengan este nombre. ***
			






 



 

///////////////////////////////////////IMPLMENTACION/////////////////////////////////////////////

FORMA COMANDOS

1. Crear el deploymente de las db.
2. Crear el service de las db el tipo de red que tendrá será la interna (clusterIp).
3. Crear el deploymente de las apps.
4. Crear el service de las apps el tipo de red que tendrá será la comunicación interna y externa (LoadBalancer).


